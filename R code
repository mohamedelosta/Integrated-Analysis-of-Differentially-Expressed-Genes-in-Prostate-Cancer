###########################################
#  - Gene Expression Profiling of Prostate#
#  - TCGA-PRAD project - RNAseq data      # 
#  - Mohamed elosta                       #    
###########################################

####load libraries ########  
library(readr)
library(org.Hs.eg.db)
library("vsn")
library(DESeq2)
library(dplyr)
library(TCGAbiolinks)
library(ComplexHeatmap)
library(rgl)
library(caret)
library(xgboost)
library(h2o)




#########loading prostate caner RNA-Seq from TCGA data base###########


##building query data

gdc.query = GDCquery(
  project = "TCGA-PRAD",
  data.category = 'Transcriptome Profiling',
  experimental.strategy = 'RNA-Seq',
  workflow.type = 'STAR - Counts',
  access = 'open')

save(gdc.query ,file = "GDCquery")

results<- getResults(gdc.query)


#downlaod the data 

GDCdownload(gdc.query)

#prepare the data

TCGA.data <- GDCprepare(gdc.query, summarizedExperiment = TRUE)

data.matrix <- assay(TCGA.data, 'unstranded')

rowData <- rowData(TCGA.data)

colData <-  colData(TCGA.data)



#considering protein coding gene only 
protein_coding = rownames(as.data.frame(rowData) %>% filter(., gene_type =='protein_coding' ))
exp.matrix <- data.matrix[protein_coding,]


### Data filteration 

# check duplciation of of gene symbols?

x=duplicated(rowData[rownames(exp.matrix),]$gene_name) 
sum(x)

#aggregation of duplicated genes

rownames(exp.matrix) <- rowData[rownames(exp.matrix),]$gene_name

exp.matrix.agg= aggregate(exp.matrix, list(rownames(exp.matrix)),FUN=max)
genes=exp.matrix.agg$Group.1
exp.matrix.agg=exp.matrix.agg[-1]
exp.matrix.agg=apply(exp.matrix.agg,2, as.numeric)
exp.matrix.agg=round(exp.matrix.agg)
rownames(exp.matrix.agg)=genes



# Calculate total read counts per gene/transcript
total_counts <- rowSums(exp.matrix.agg)

# Set a threshold for minimum read counts (adjust as needed)
min_counts_threshold <- 100

# Filter genes/transcripts based on minimum read counts
filtered_data <- exp.matrix.agg[total_counts >= min_counts_threshold, ]


#Exploratory data analysis 
tumor.samples <- as.data.frame(colData) %>% filter(., shortLetterCode == 'TP') %>% group_by(sample_id)
tumorLong <- filtered_data_long %>% filter(., Sample %in% tumor.samples$sample )

normalLong <- filtered_data_long %>% filter(., !(Sample %in% tumor.samples$sample) )

ggplot(tumorLong, aes(x = Expression)) +
  geom_density(alpha = 0.5) +
  scale_x_log10() +
  labs(title = "Density Plot of Tumor samples", x = "Expression", y = "Density") +
  theme_minimal()

ggplot(normalLong, aes(x = Expression,color= Sample)) +
    geom_density(alpha = 0.5) +
    scale_x_log10() + 
    guides(color = FALSE) +
    labs(title = "Density Plot of Tumor samples", x = "Expression", y = "Density") +
    theme_minimal()

ggplot(normalLong, aes(x = Expression,color= Sample)) +
   geom_density(alpha = 0.5) +
   scale_x_log10() + 
   guides(color = FALSE) +
   labs(title = "Density Plot of Normal samples", x = "Expression", y = "Density") +
   theme_minimal()





# Determine the number of sets (batches) with 100 samples each
num_sets <- ceiling(ncol(filtered_data_long) / 100)

# Create a list to store individual boxplot plots for each set
plot_list <- list()

# Loop through each set of 100 samples, create boxplot, and store the plot
for (i in 1:num_sets) {
  start_index <- (i - 1) * 100 + 1
  end_index <- min(i * 100, ncol(filtered_data_long))
  
# Subset data for the current set of 100 samples
set_data <- filtered_data_long[, start_index:end_index]
  
# Create boxplot for the current set
plot <- ggplot(set_data, aes(x = Sample, y = Expression)) +
  geom_boxplot() +
  scale_y_log10()+
  labs(title = paste("Boxplot of Samples", start_index, "to", end_index), x = "Samples", y = "Expression") +
  theme_minimal()
  
  # Store the plot in the list
  plot_list[[i]] <- plot
}
plot_grid(plotlist = plot_list, ncol = 2)




#### Do differential analysis using Deseq2 ####

## using short letter code
colnames(filtered_data) = colData$shortLetterCode 
filtered_data = filtered_data[,-which(colnames(filtered_data) == 'TM')]

## removing the only metastatic sample
colData <- colData[-which(colData$shortLetterCode== 'TM'),]
rownames(colData) = colData$shortLetterCode 

cond1="Solid Tissue Normal" 
cond2="Primary Tumor"

dds= DESeqDataSetFromMatrix( countData = filtered_data, colData = colData , design = ~ sample_type)
dds.run = DESeq(dds)

### specifying the contrast
res=results(dds.run, contrast = c("sample_type",cond1 ,cond2) )

# remove nulls
res=res[complete.cases(res), ]
summary(res)

res.df=as.data.frame(res)


### DEGs visualization ###

# dispersion estimation plot
dds <- estimateSizeFactors(dds)
dds <- estimateDispersions(dds)
plotDispEsts(dds)



#MA plot
plotMA(res, ylim=c(-1,1)) 
summary (res)

### Volcano Plot
keyvals <- ifelse(
  res$log2FoldChange < -1.5 & res$padj < 0.01, 'green4',
  ifelse(res$log2FoldChange > 1.5 & res$padj < 0.01 , 'red3',
         'black'))
keyvals[is.na(keyvals)] <- 'black'
names(keyvals)[keyvals == 'red3'] <- 'high'
names(keyvals)[keyvals == 'black'] <- 'mid'
names(keyvals)[keyvals == 'green4'] <- 'low'

EnhancedVolcano(res.df,
                lab = rownames(res.df),
                x = 'log2FoldChange',
                y = 'padj',
                colCustom = keyvals,
                pCutoff =  0.01,
                FCcutoff = 1.5,
                pointSize = 2.0,
                labSize = 6.0,
                col=c('black', 'black', 'black', 'red3'),
                colAlpha = 1)


### DEGs selection criteria ###

res.degs=res[res$padj< 0.01 & abs(res$log2FoldChange)>log2(3),]
res.degs=res.degs[order(res.degs$padj), ]

degs.genes=rownames(res.degs)

##export degs for gene enrichment analysis
write.table(degs.genes, file="degs_prostate.txt", quote = F, col.names = F, row.names = F)

#### get the normalized and logged transformed values of all exp data


ntd=normTransform(dds)
exp.norm= assay(ntd)


 
### get the normalized expression levels of the degs ###################
degs.exp=exp.norm[degs.genes,]

##creating a heatmap for the top 500 DEG genes

#  get the expression profiles of the top 500 degs only and create heatmap
sorted_genes <- order(res.degs[,6], decreasing = FALSE)

# Get the top 500 DEGs based on the sorted order
top_100_degs <- sorted_genes[1:100]

# Extract the information for the top 500 DEGs
top_100_degs_info <- degs.exp[top_100_degs, ]



phenotable.sub=colData[colData$sample_type %in% c("Primary Tumor", "Solid Tissue Normal"),]
sample_type_colors <- c("Primary Tumor" = "red", "Solid Tissue Normal" = "green")
column_ha <- HeatmapAnnotation(Sample.type = phenotable.sub$sample_type, col = list(Sample.type = sample_type_colors))
Heatmap(t(scale(t(top_100_degs_info))),
        row_names_gp = gpar(fontsize = 2.5),
        name = "Z-score",
        column_names_gp = gpar(fontsize = 6),
        top_annotation = column_ha,
        column_split = colData$sample_type)

###creating  2D PCA for all degs and look how it segregates the healthy and tumor samples 
exp.pca=prcomp(t(degs.exp),scale=F)
sample_type_colors <- c("Primary Tumor" = "red", "Solid Tissue Normal" = "green3")
autoplot(exp.pca, data = as.data.frame(colData), colour = 'sample_type', frame = FALSE) +
  scale_color_manual(values = sample_type_colors)


###creating  3D PCA  all degs and look how it segregates the healthy and tumor samples 
exp.pca <- princomp(degs.exp,cor=T,scores = TRUE)
mycolors= rep("green3",dim(colData)[1])
mycolors[which(colData$sample_type=="Primary Tumor")]="red"


plot3d(exp.pca$loadings[,1:3], pch=20 )

plot3d(exp.pca$loadings[,1:3], pch=20 ,col=mycolors)
plot3d(exp.pca$loadings[,1:3], type="s",radius="0.004" ,col=mycolors)
snapshot3d()




###enrichment analysis using enrichR



### visualize the enrichment analysis results using GOPLOT  
library(GOplot)
load('degs_prostate100.txt')
# Load the dataset
degs_CC =read.delim("~/GO_CC2023.txt") %>% mutate(., Category= "CC") 
degs_MF =read.delim("~/GO_MF2023.txt")%>% mutate(., Category= "MF") 
degs_BP =read.delim("~/GO_BP2023.txt")%>% mutate(., Category= "BP") 

degsGOterms=  merge(degsGOterms,degs_CC , all = TRUE)


#creating GOplot input

#terms dataFrame

# Separate the GO term and ID into two columns
degsGOterms <- separate(degsGOterms,Term, into = c("Term", "ID"), sep = " \\(")

# Remove the closing parenthesis from the GO_ID column
degsGOterms$ID <- gsub("\\)", "", degsGOterms$ID)



degsGOterms <- rename(degsGOterms,adj_pval=Adjusted.P.value )
degsGOterms$Genes <- gsub(', ',',',degsGOterms$Genes)
degsGOterms <- degsGOterms[,c(1,2,5,10,11)]
#gene list dataFrame
go.genes <- res.degs[1:100,] %>% select(c(2))
go.genes <- go.genes %>% mutate(ID = rownames(go.genes))
go.genes <- rename(go.genes, 'logFC' ='log2FoldChange' )

rownames(go.genes)= NULL



### Generate the plotting object

circ <- circle_dat(degsGOterms,go.genes)


#Bar plot
GOBar(subset(circ, category == 'MF'))
GOBar(circ2, display = 'multiple')
GOBar(subset(circ, category == 'BP'))

GOBar(subset(circ2, category == 'BP'), order.by.zscore = F)




#Bubble plots

GOBubble(circ2, labels = 3)

GOBubble(circ2, title = 'Bubble plot', colour = c('orange', 'darkred', 'gold'), display = 'multiple', labels = 1.3)
GOBubble(reduced_circ, title = 'Enriched Terms', display = 'multiple', bg.col = T, labels = 3)  
#Circle plot
GOCircle(circ2)
reduced_circ <- reduce_overlap(circ, overlap = 0.75)
#GOBubble
GOBubble(reduced_circ, labels = 1.6)

#enrichR
library(enrichR)
dbs <- c("GO_Molecular_Function_2018", "GO_Cellular_Component_2018", "GO_Biological_Process_2018")
enriched <- enrichr(degs.genes[1:100],dbs)
enriched[[1]]
plotEnrich(enriched[[2]], showTerms = , numChar = 20, y = "Count", orderBy = "P.value")







##machine learning models to estimate the importance of degs.
library(caret)

#preparing the data set

deg.train <- as.data.frame(t(degs.exp)) %>% mutate(class = colData$sample_type)

#training and testing data sets

# Set the seed for reproducibility
set.seed(123)

# Create indices for splitting
indices <- createDataPartition(deg.train$class, times = 1, p = 0.7, list = FALSE)

# Split the data based on indices
train <- deg.train[indices, ]  # 70% for training

# Exclude training indices to get the remaining data
remaining_data <- deg.train[-indices, ]

# Further split the remaining data into testing (20%) and validation (10%)
indices_remaining <- createDataPartition(remaining_data$class, times = 1, p = 0.6666667, list = FALSE)
test <- remaining_data[indices_remaining, ]  # 20% for testing
validation <- remaining_data[-indices_remaining, ]  # 10% for validation

#training models

algorithms <-c('rf','svmLinear')

train_control <- trainControl(method="repeatedcv", number=10, repeats=3, classProbs = TRUE)

model <- caretList(class ~ ., data = train, methodList = algorithms, trControl = train_control)

train$class <- make.names(train$class)


svm <- train(class ~ ., 
              data = train,
              method = "svmRadial",
              trControl = train_control)



#encoding trainset
trian_encoded <- model.matrix(~ class, data = train)

#encoding testset 
test_encoded <- model.matrix(~ class, data = test)


xgb <-  xgboost(data = as.matrix(train[,-1225]),
                label = trian_encoded[,2],
                max_depth = 15,
                nround = 25)

##predictions

pred.rf <- predict(model$rf, newdata = test)

pred.svm <- predict(svm2, newdata = test)

pred.xgb <- predict(xgb, newdata = as.matrix(test[,-1225]))
binary_xgbpredictions <- ifelse(pred.xgb >= 0.5, 1, 0)


### model evluation ###
confusionMatrix.rf <- confusionMatrix(as.factor(pred.rf), as.factor(test$class))
confusionMatrix.svm <- confusionMatrix(as.factor(pred.svm), as.factor(test$class))
confusionMatrix.xgb <-confusionMatrix(as.factor(binary_xgbpredictions), as.factor(test_encoded[,2]))
roc_svm <- roc(response = factor(test$class), predictor = as.numeric(pred.svm))
roc_rf <- roc(response = factor(test$class), predictor = as.numeric(pred.rf))
roc_xgb <- roc(response = factor(test_encoded[,2]), predictor = as.numeric(binary_xgbpredictions), print.auc=TRUE)


# Plot the ROC curve for the first model
par(pty="s")
plot(roc_rf, col = "red", main = "ROC Curves")
# Add ROC curves for the other two models
lines(roc_svm, col = "blue")
lines(roc_xgb, col = "green")

# Add a legend
legend("bottomright", legend = c("RF (AUC=0.9)" , "SVM (AUC=0.995)", "xgb (AUC=0.96)"), col = c("red", "blue", "green"), lwd = 1)
 


# Get feature importance scores 

importance_scores <- varImp(model$rf)$importance

# Convert importance scores to a data frame 
importance_df <- as.data.frame(importance_scores)
importance_df$Features <- rownames(importance_df)

importance_df <- importance_df[order(-importance_df$Overall), ]

# Select the top 10 features
top_10_features <- head(importance_df, 10)


# Plotting the top 10 features
ggplot(top_10_features, aes(x = Overall, y = Features)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  labs(x = "Importance Score", y = "Features", title = "Top 10 Variable Importance Plot") +
  theme_minimal()


### deep learing using h2o package ###

h2o.init()
train_h2o <- as.h2o(train)
validation_h2o <- as.h2o(validation)
train$class <- as.factor(train$class)
validation$class <- as.factor(validation$class)
deg.train$class <- as.factor(deg.train$class)
train$class <- make.names(train$class)
validation$class <- make.names(validation$class)

deep <- h2o.deeplearning(
  x= colnames(train[1:1224]),
  y= names(train[1225]),
  training_frame = train_h2o,
  validation_frame = validation_h2o,
  epochs =5)

plot(deep)
test_h2o <- as.h2o(test)
perf <- h2o.predict(deep, newdata = test_h2o)
performance <- h2o.performance(deep , newdata =test_h2o )
plot(performance)
test$class <- make.names(test$class)

h2o.varimp_plot(deep)
